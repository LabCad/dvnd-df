\section{Busca local} \label{sec:buscaLocal}

\subsection{Vizinhança} \label{subsec:vizinhanca}

Seja $S$ o espaço de soluções de um problema de otimização $\Pi$, e $s \in S$ uma solução qualquer, considere a função objetivo $f: S \rightarrow \mathbb{R}$ que atribui um valor para cada solução.
Denotamos então por $N^x(s)$ o conjunto de soluções vizinhas de $s$ para a vizinhança $x$ com $N^x(s) \subset S$, em que as soluções dessa vizinhança podem ser obtidas de $s$ a partir da aplicação de determinadas operações.
Uma solução $s'$ é vizinha de $s$ (isto é $s' \in N^x(s)$) segundo uma vizinhança $s$ se $s'$ é alcançável a partir de $s$ fazendo uso de uma pequena perturbação nesta última.

\input{conceitos/movimento.tex}

Assim podemos estender a definição da vizinhança $x$ para:
\begin{equation}  \label{eq:vizinhanca}
N(s) = \{ m_i \circ s \mid \forall m_i \in M \}
\end{equation}

Cabe aqui destacar que a independência de movimentos é uma relação dada dois a dois entre os movimentos, logo não existe transitividade na relação de independência de destes, ou seja, se temos dois movimentos independentes $m_1 \parallel m_2$ e outro movimento $m_3$ tal que $m_3 \parallel m_2$ então \textbf{não} implica que $m_1 \parallel m_3$.
Pode existir um conflito, logo os movimentos $m_1 \nparallel m_3$ ou seja, seriam conflitantes.
Assim em termos de conflitos entre movimentos podemos escrever:
\begin{equation}
m_1 \parallel m_2 \land m_2 \parallel m_3 \centernot\implies m_1 \parallel m_3
\end{equation}

Tenhamos como exemplo o caso a seguir para a vizinhança de Swap, sendo eles $Swap(2,3), Swap(3,6), Swap(4,5)$, neste caso podemos ver que $Swap(2,3) \parallel Swap(4,5)$ e que $Swap(4,5) \parallel Swap(3,6)$ contudo $Swap(2,3) \nparallel Swap(3,6)$.

Para fins dessa dissertação, por questão de simplificação de notação, deste ponto em diante as referências a \textit{movimentos independentes} estão referenciando \textit{movimentos estritamente independentes}.

% Estou achadno a prova do teorema muito fraca
% \input{conceitos/teoremaIndependenciaMovimentos.tex}

\subsection{First Improvement vs Best Improvement} \label{subsec:firstBestImprovement}

As estratégias \textit{First Improvement} (Primeira melhora) e \textit{Best Improvement} (Melhor melhora) recebem como parâmetro a solução da iteração corrente para gerar seus vizinhos e escolhem uma solução a ser retornada conforme um critério específico, a saber, a primeira solução a melhorar a atual e a melhor solução encontrada na vizinhança, respectivamente.

\begin{algorithm}[htpb]
\caption{First Improvement para um problema de minimização}
\label{alg:firstImprovement}
\begin{algorithmic}[1]
    \Function{FirstImprovement}{Solução: $s$, Operador de vizinhança: $x$}
        % \For{$s' \in N^x(s)$} \Comment{Para cada solução $s'$ vizinha de $s$}
        %     \If{$f(s') < f(s)$} \Comment{Se a solução for melhor que a atual}
        %         \Return{$s'$}
        %     \EndIf
        % \EndFor
        \For{$m_i \in M$} \Comment{Para cada movimento $m_i \in M$}
            \If{$\widehat{m_i}(s) < 0$} \Comment{Se a solução for melhor que a atual}
                \Return{$m_i \circ s$}
            \EndIf
        \EndFor
        \Return{$s$} \Comment{Caso não consiga melhorar retorna a própria solução}
    \EndFunction
\end{algorithmic}
\end{algorithm}

Podemos ver o pseudocódigo do \textit{First Improvement} no Algoritmo~\ref{alg:firstImprovement} que consiste de enumerar os vizinhos até encontrar o primeiro que seja melhor que a solução atual, este então é retornado como resposta do método.
O método de \textit{Best Improvement} (Algoritmo~\ref{alg:bestImprovement}) consiste em enumerar toda a vizinhança guardando a informação do melhor encontrado até o momento, e então retornar o melhor resultado encontrado.

\begin{algorithm}[htpb]
\caption{Best Improvement para um problema de minimização}
\label{alg:bestImprovement}
\begin{algorithmic}[1]
    \Function{BestImprovement}{Solução: $s$, Operador de vizinhança: $x$}
        % \Let{$s^{best}$}{$s$} \Comment{Melhor solução encontrada}
        % \For{$s' \in N^x(s)$} \Comment{Para cada solução $s'$ vizinha de $s$}
        %     \If{$f(s') < f(s)$} \Comment{Se a solução for melhor que a atual altera a melhor solução encontrada}
        %         \Let{$s^{best}$}{$s'$}
        %     \EndIf
        % \EndFor
        \Let{$s^{best}$}{$s$} \Comment{Melhor solução encontrada}
        \For{$m_i \in M$} \Comment{Para cada movimento $m_i \in M$}
            \If{$\widehat{m_i}(s) < f(s^{best}) - f(s)$} \Comment{Se a solução for melhor que a atual altera a melhor solução encontrada}
                \Let{$s^{best}$}{$m_i \circ s$}
            \EndIf
        \EndFor
        \Return{$s^{best}$} \Comment{Retorna a melhor solução encontrada}
    \EndFunction
\end{algorithmic}
\end{algorithm}

O \textit{First Improvement} pode ser uma opção ao método de \textit{Best Improvement} quando a enumeração de toda a vizinhança é uma atividade muito custosa.
% Posso afirmar isso?
Embora não haja um paralelo para a definição matemática formal da solução $s'$ retornada pelo \textit{First Improvement} esta pode ser definida para o \textit{Best Improvement} de maneira simples por $s' \in N^x(s) \mid f(s') < f(s), \forall s \in N^x(s)$, o que, como veremos a seguir na seção~\ref{sec:otimoLocalGlobal}, corresponde ao ótimo local para a solução $s$ segundo a vizinhança $x$.
Em termos de movimento temos $s' = m' \circ$ com $\widehat{m'}(s) < \widehat{m_i}(s) \mid \forall m_i \in M$.

\subsection{Random Selection}

Nesta estratégia \textit{Random Selection} (Escolha Aleatória) é selecionada uma solução aleatoriamente entre aquelas que melhoram a solução atual.

\begin{algorithm}[htpb]
\caption{Random Selection para um problema de minimização}
\label{alg:randomSelection}
\begin{algorithmic}[1]
    \Function{RandomSelection}{Solução: $s$, Operador de vizinhança: $x$}
        \Let{$S_{imp}$}{$\emptyset$} \Comment{Conjunto com soluções de melhora}
        \For{$m_i \in M$} \Comment{Para cada movimento $m_i \in M$}
            \If{$\widehat{m_i}(s) < 0$} \Comment{Se a solução for melhor que a atual}
                \Let{$S_{imp}$}{$S_{imp} \cup \{ m_i \circ s\}$} \label{alg:randomSelection:salvaMelhora} \Comment{Adiciona ao conjunto de soluções de melhora}
            \EndIf
        \EndFor
        \Return{$Any(S_{imp})$} \Comment{Retorna uma das soluções de melhora}
    \EndFunction
\end{algorithmic}
\end{algorithm}

A estratégia \textit{Random Selection} (mostrada no Algoritmo~\ref{alg:randomSelection}) navega pelas soluções e na mantém as melhores soluções que melhoram a solução atual, conforme linha~\ref{alg:randomSelection:salvaMelhora}, para ao final retornam uma deste grupo.

\subsection{Multi Improvement}

Uma alternativa ao \emph{Best Improvement}, \emph{First Improvement} e ao \emph{Random Selection} é o \emph{Multi Improvement}~\cite{rios2015}.
A ideia é combinar um conjunto de movimentos independentes e executá-los simultaneamente sobre a solução de entrada.
Note que, embora consista na aplicação de diversos movimentos, somente uma única solução vizinha é gerada.
O \emph{Multi Improvement} pode ser utilizado em qualquer contexto que o \emph{Best Improvement} ou \emph{First Improvement} se encaixe (etapa de Exploração de Vizinhança ou {\it Neighborhood Exploration}), porém caso só exista um único movimento independente na vizinhança, ele terá comportamento equivalente ao Best Improvement.
Assim a solução $s'$ retornada por uma iteração do \emph{Multi Improvement} após ser aplicado a uma solução $s$ é dada por $s' = m_1 \circ m_2 \circ \dots m_k \circ s$ com os movimentos independentes $\{ m_1, m_2, \dots, m_k \} \subset M$.

O \emph{Multi Improvement} se encaixa particularmente bem com o conceito de \emph{SIMD} (\emph{Single Instruction Multiple Data}), presente nas GPUs, sendo sua complexidade similar ao \emph{Best Improvement} (todos movimentos da vizinhança são enumerados), seguido de uma etapa de junção (ou {\it merge}) dos movimentos independentes.
Podem existir cenários em que o \emph{Best Improvement} seja mais eficiente (com poucos movimentos independentes), embora já tenha sido demonstrado na literatura que mesmo casos com apenas dois movimentos independentes acabam mais promissores no \emph{Multi Improvement} do que no \emph{Best Improvement}. % Não seria importante colocar a referência disso?

\subsection{Passo iterativo} \label{subsec:passoIterativo}
% Posso fazer essa definição que estou fazendo aqui?
% Pensei em fazer isso para facilitar explicar algumas coisas mais pra frente

Em geral, um algoritmo de busca local é um processo iterativo pesado que tem como objetivo encontrar uma solução melhor que a atual dentro de um espaço de busca.
A solução recebida como entrada pode ser aleatória ou advinda de alguma heurística construtiva, a intenção do processo é aprimorar o resultado encontrado.

Cada iteração da busca local tenta encontrar a melhor solução mediante alguma alteração na solução atual, então o processo se repete na solução gerada até que nenhuma melhora seja possível.

\begin{algorithm}[htpb]
\caption{Busca local definida de forma genérica}
\label{alg:localSearch}
\begin{algorithmic}[1]
    \Function{LocalSearch}{Solução: $s$}
        \While{$f(Alterar(s)) < f(s)$} \Comment{Cada iteração corresponde a um passo iterativo da busca local}
            \Let{s}{$Alterar(s)$}
        \EndWhile
        \Return{$s$} \Comment{Retorna a melhor solução encontrada}
    \EndFunction
\end{algorithmic}
\end{algorithm}

Supondo que $Alterar(s)$ (apresentado do Algoritmo~\ref{alg:localSearch}) retorna uma solução melhor que a atual segundo alguma alteração, convencionemos então chamar de \textbf{passo iterativo} cada iteração da busca local em que o processo obtém uma solução melhor que a atual e salva o melhor resultado encontrado até o momento.
Assim para uma solução $s$ o passo iterativo é dado pela Equação~\ref{eq:passoIterativo}.

\begin{equation} \label{eq:passoIterativo}
\rho(s) = min(s, Alterar(s)) \implies f(\rho(s)) \le f(s)
\end{equation}
