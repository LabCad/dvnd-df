pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:66, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 8574514-[49 55 45 60 94 10  4 54 23 25 81  7 91 37  9 73 19 62 17 42 14 21  3 72 58
 78 68 11 35 76  8 63 46 52 53 70 67 36 51 99 24 77 83 59 30 64 43 44 56 13
 74 65 27 50 96 85 82 18 20 47 86 38 93  1 84 87 80 75  0 88 92 69 61 98 90
 57 40 95 89  2  6 12 97 34 26 41 22  5 71 16 29 32 39 31 79 28 66 15 33 48] - 8574514
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f0871d43ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 8574514-[49 55 45 60 94 10  4 54 23 25 81  7 91 37  9 73 19 62 17 42 14 21  3 72 58
 78 68 11 35 76  8 63 46 52 53 70 67 36 51 99 24 77 83 59 30 64 43 44 56 13
 74 65 27 50 96 85 82 18 20 47 86 38 93  1 84 87 80 75  0 88 92 69 61 98 90
 57 40 95 89  2  6 12 97 34 26 41 22  5 71 16 29 32 39 31 79 28 66 15 33 48]
Final time: 1.69262814522s - Best: 958064-[49  0 12 78 87 26 23 40 83 72 38 90 53 62 15 76 42 70  3 92 43 59 52 61 36
 18 50 29 99  1 47 91 86 25 54  8 19 24 17  5 39 82  2 58 84 95 85 64 13 67
 32 44 98 77 30 56 71 79 75 45 51  7 65 37 80 33 10 89 16 93 31 96 97 48 69
 88 22 41 21 57 28 35 66 74  6 73 60 68 14 63 81 46 11 27 20 55 94  9  4 34]
Value - initial: 8574514, final: 958064, improveup: 8.94983424907

data-line;i;8574514;f;958064;t;1.69262814522;c;-2;fv;[958064L];cv;-1;imp;8.94983424907;type;rvnd;inum;1;w;1

time;1.69262814522;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
