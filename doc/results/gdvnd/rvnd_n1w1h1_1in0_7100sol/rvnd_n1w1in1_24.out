pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:24, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 8519514-[82 89 42 48 26 16  4 20 50 95 34  7 39 54 65 55 30 35 23 67 53 69 90 99  0
 77 33 14 70  6 44 32 57  5 61 40 81 59 47 37 56 63 88 76 22 58 64 80 84 12
 41 24 36 94  1 46 73 43 51 87 17 68 45 13 85 28 92 62 18 98 78  3 27 25  2
 93 74 15 38 21 79 52 31 91 11 97 19 96 75  8 71 10 66 83 49 29 72 86  9 60] - 8519514
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f9610199ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 8519514-[82 89 42 48 26 16  4 20 50 95 34  7 39 54 65 55 30 35 23 67 53 69 90 99  0
 77 33 14 70  6 44 32 57  5 61 40 81 59 47 37 56 63 88 76 22 58 64 80 84 12
 41 24 36 94  1 46 73 43 51 87 17 68 45 13 85 28 92 62 18 98 78  3 27 25  2
 93 74 15 38 21 79 52 31 91 11 97 19 96 75  8 71 10 66 83 49 29 72 86  9 60]
Final time: 1.29126811028s - Best: 1037868-[82  2 39  5 58 84 17 19 24 81 13 67 32 44 98 30 56 71 75 79 77 64 85 95 15
 62 53 90 14 83 40 87 23 26 80 33 37 65 51  7 22 41 88 69 48 97 96 31 93 16
 89 10 49  0 12 78 72 38 76 42 70  3 92 43 59 61 36 50 18 91 47  1 99 29 34
 52  4 54 86 25 94 55 27 11 46 20  9  8 63 68 45 60 73  6 74 66 35 28 57 21]
Value - initial: 8519514, final: 1037868, improveup: 8.20866815433

data-line;i;8519514;f;1037868;t;1.29126811028;c;-2;fv;[1037868L];cv;-1;imp;8.20866815433;type;rvnd;inum;1;w;1

time;1.29126811028;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
