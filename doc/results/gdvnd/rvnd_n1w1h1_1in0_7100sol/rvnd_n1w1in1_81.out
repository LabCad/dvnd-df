pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:81, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 8868473-[11 16 22 86 64  9 61 20 19 89 52 51  2 39 53 36 21 91 45 77 80 24 90 78 10
 49 30 12 46 35 34 28 26 50  0 23 84 59  8 31 44 63 38 62 73 32 65 68  7 97
 81 72 55 79 83 75 42 48 70 25 15 18 93 88 71 85 92 47 96  4 98 17 76 54 69
 99 41 29  6 87 13 37 57 58 27 60 95 66 14 82 94 40 56 33 43  5 74  1  3 67] - 8868473
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7fc759382ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 8868473-[11 16 22 86 64  9 61 20 19 89 52 51  2 39 53 36 21 91 45 77 80 24 90 78 10
 49 30 12 46 35 34 28 26 50  0 23 84 59  8 31 44 63 38 62 73 32 65 68  7 97
 81 72 55 79 83 75 42 48 70 25 15 18 93 88 71 85 92 47 96  4 98 17 76 54 69
 99 41 29  6 87 13 37 57 58 27 60 95 66 14 82 94 40 56 33 43  5 74  1  3 67]
Final time: 0.83481502533s - Best: 1016963-[11 27 46 20  9  8 54 25 86 91 18 36 50  1 99 29 34 61 59 52  4  2 82 39  5
 58 84 95 85 64 13 67 32 44 98 77 30 56 71 79 75 45 51  7 65 37 33 80 26 23
 83 14 62 53 90 76 42  3 43 92 70 38 72 40 87 78 12  0 49 93 31 96 97 48 69
 88 89 16 10 22 41 21 57 28 35 66 74  6 73 60 68 15 63 17 81 24 19 55 94 47]
Value - initial: 8868473, final: 1016963, improveup: 8.72054637189

data-line;i;8868473;f;1016963;t;0.83481502533;c;-2;fv;[1016963L];cv;-1;imp;8.72054637189;type;rvnd;inum;1;w;1

time;0.83481502533;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
