pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:3, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 8154844-[97 46 67 75 62 18  3 44 34 40 90 94 58 23 53 50 66 26 77 55 54 87  9 93 43
 84 41 74 80 13 70 20 14 12 30 76  4 11 47 59 27 96 82 85 24 88 86 95 83 21
 16 78 60  6 61 71 98 51 28 36 68  1 49 39 32 89 99 38 45 64 17 19 31 69 57
 48  7 29 42 63  0 52 91 56 33  5 81 25 73 79  8 92 72 22 35 65 37 15  2 10] - 8154844
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f5a3fa61ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 8154844-[97 46 67 75 62 18  3 44 34 40 90 94 58 23 53 50 66 26 77 55 54 87  9 93 43
 84 41 74 80 13 70 20 14 12 30 76  4 11 47 59 27 96 82 85 24 88 86 95 83 21
 16 78 60  6 61 71 98 51 28 36 68  1 49 39 32 89 99 38 45 64 17 19 31 69 57
 48  7 29 42 63  0 52 91 56 33  5 81 25 73 79  8 92 72 22 35 65 37 15  2 10]
Final time: 1.43148517609s - Best: 989225-[97 48 69 88 10 89 16 96 31 93 49  0 12 78 87 26 23 40 83 72 38 90 53 62 15
 76 42 70  3 92 43 59 52  4 61 34 29 99  1 50 36 18 91 86 25 54  8  9 19 24
  2 82 39  5 17 84 58 63 95 85 64 13 67 32 44 98 77 30 56 71 79 75 60 73  6
 74 66 35 28 57 21 41 22 37 33 80 65  7 51 45 68 14 81 46 11 27 20 55 94 47]
Value - initial: 8154844, final: 989225, improveup: 8.24366953929

data-line;i;8154844;f;989225;t;1.43148517609;c;-2;fv;[989225L];cv;-1;imp;8.24366953929;type;rvnd;inum;1;w;1

time;1.43148517609;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
