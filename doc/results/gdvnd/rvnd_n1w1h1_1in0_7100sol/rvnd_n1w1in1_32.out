pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:32, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 7882645-[ 9 89 57 52 58 70 90  2 37 14 62 54 93 56 95 11 68 48 97 80 20 94 81 47 63
 91  0 10  4 17 67 82 96 31 12 75 60  8 21 86 88 42 61 46  1 30 43 35 71  3
 69 87 27 13 23 16 72 64 41 29  6 40 18 76 85 83 45 65 50 25 99 33 26 51 44
 34 28 36 53 84 74 79 32 77 49 59 78 39 73 38 22 55  7 19 15  5 92 24 66 98] - 7882645
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f9222afbad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 7882645-[ 9 89 57 52 58 70 90  2 37 14 62 54 93 56 95 11 68 48 97 80 20 94 81 47 63
 91  0 10  4 17 67 82 96 31 12 75 60  8 21 86 88 42 61 46  1 30 43 35 71  3
 69 87 27 13 23 16 72 64 41 29  6 40 18 76 85 83 45 65 50 25 99 33 26 51 44
 34 28 36 53 84 74 79 32 77 49 59 78 39 73 38 22 55  7 19 15  5 92 24 66 98]
Final time: 1.67126297951s - Best: 977651-[ 9 25 86 54  8 19 24  2 82 39  5 17 84 58 63 42 76 90 53 62 15 95 85 64 13
 67 32 44 98 77 30 56 71 79 75 60 73  6 74 66 35 28 57 21 41 22  7 51 65 37
 80 33 10 16 89 88 69 48 97 96 31 93 49  0 12 78 87 26 23 40 83 14 72 38 70
  3 92 43 59 52  4 61 36 18 50 34 29 99  1 47 91 94 55 20 46 27 11 81 68 45]
Value - initial: 7882645, final: 977651, improveup: 8.06284144342

data-line;i;7882645;f;977651;t;1.67126297951;c;-2;fv;[977651L];cv;-1;imp;8.06284144342;type;rvnd;inum;1;w;1

time;1.67126297951;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
