pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:62, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 7865031-[18 51  8  5 59 31 60 73  7 70  0 28 29 40 52  3 94 83 96 95 41 15 44  6 39
 23 75 63 78 33 88 86 58 16 26 72 30 62 13 48 14 91 71 64 89 47 81 10  9 34
 50 85 67  2 93 21 43 57 22 66 90 54 82 36 56 68 92  4 76 46 42 61 24 80 53
 79 38 11 32 25 69 98 87 97 74 45 35 99  1 55 77 19 84 49 12 17 27 37 65 20] - 7865031
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f36ae592ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 7865031-[18 51  8  5 59 31 60 73  7 70  0 28 29 40 52  3 94 83 96 95 41 15 44  6 39
 23 75 63 78 33 88 86 58 16 26 72 30 62 13 48 14 91 71 64 89 47 81 10  9 34
 50 85 67  2 93 21 43 57 22 66 90 54 82 36 56 68 92  4 76 46 42 61 24 80 53
 79 38 11 32 25 69 98 87 97 74 45 35 99  1 55 77 19 84 49 12 17 27 37 65 20]
Final time: 1.70979690552s - Best: 953538-[18 36 50 29 99  1 47 91 86 25 54  8 19 24 17 84 58  5 39 82  2  4 52 59 43
 92  3 70 42 76 90 53 62 15 95 85 64 13 67 32 44 98 30 77 79 75 45 51  7 65
 37 33 80 26 23 83 40 87 78 12  0 49 93 31 96 97 48 69 88 89 16 10 22 41 21
 57 28 35 66 74  6 73 60 71 56 81 46 11 27 55 94  9 61 34 38 72 14 68 63 20]
Value - initial: 7865031, final: 953538, improveup: 8.24826173682

data-line;i;7865031;f;953538;t;1.70979690552;c;-2;fv;[953538L];cv;-1;imp;8.24826173682;type;rvnd;inum;1;w;1

time;1.70979690552;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
