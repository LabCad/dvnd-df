pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:7, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 7736197-[74 26 70 81 47 63 52  4 42  0 49 96 43 75 20 61 79 64 19 24 17 21 15 56 92
 57  2 85 90 83 93 12 44 53 18  7 66 14 46 36 88 10 91  9 33 69 29 37 98 67
 78  8 16 77 48 76 86 23 72 51 25 22 31 50 84 41 71 89 60 97 13 58 68 34 54
 35 99 59 94  3 11 39 30  1 28 82 27 45 95 38 62 40 55 32  6 87 73 65 80  5] - 7736197
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7fe174887ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 7736197-[74 26 70 81 47 63 52  4 42  0 49 96 43 75 20 61 79 64 19 24 17 21 15 56 92
 57  2 85 90 83 93 12 44 53 18  7 66 14 46 36 88 10 91  9 33 69 29 37 98 67
 78  8 16 77 48 76 86 23 72 51 25 22 31 50 84 41 71 89 60 97 13 58 68 34 54
 35 99 59 94  3 11 39 30  1 28 82 27 45 95 38 62 40 55 32  6 87 73 65 80  5]
Final time: 1.22094202042s - Best: 1042035-[74 35 66  6 71 56 30 77 98 44 32 67 13 64 85 95 84 58  5 39 82  2  4 52 61
 36 50 18  1 99 29 34 59 43 92  3 70 42 76 90 53 62 14 83 40 78 12 87 23 26
 80 33 37 65  7 51 45 60 73 22 41 10 16 89 88 69 48 97 96 31 93 49  0 72 38
 15 63 17 24 19  8 54 86 25  9 20 46 11 27 55 94 47 91 81 79 75 68 28 57 21]
Value - initial: 7736197, final: 1042035, improveup: 7.42412394977

data-line;i;7736197;f;1042035;t;1.22094202042;c;-2;fv;[1042035L];cv;-1;imp;7.42412394977;type;rvnd;inum;1;w;1

time;1.22094202042;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
