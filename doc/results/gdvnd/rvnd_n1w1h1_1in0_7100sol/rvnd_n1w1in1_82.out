pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:82, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 7984337-[77 71 76 42 31 81 87 85 80 73 51 74 47 83 25 12 95  6 60 35 62 90 70 38 93
 39 61 10 82 49 97  9 45 59 89 57 34 23 24 64 33 79  4 15  3 96 18 19 21 40
 13 94 92  5 75 20 27 56  2  1 17 63 78 32 48 28 69 88 52  8 54 41 11 86 36
 99  0 29 26 72 53 91 43 55 68 65 46 66 50 16 44 98 84 37 58 67 22 30 14  7] - 7984337
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f89e6469ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 7984337-[77 71 76 42 31 81 87 85 80 73 51 74 47 83 25 12 95  6 60 35 62 90 70 38 93
 39 61 10 82 49 97  9 45 59 89 57 34 23 24 64 33 79  4 15  3 96 18 19 21 40
 13 94 92  5 75 20 27 56  2  1 17 63 78 32 48 28 69 88 52  8 54 41 11 86 36
 99  0 29 26 72 53 91 43 55 68 65 46 66 50 16 44 98 84 37 58 67 22 30 14  7]
Final time: 0.72500705719s - Best: 1039851-[77 98 30 79 75 45 51  7 65 37 80 33 49  0 12 78 87 26 23 40 83 72 38 90 53
 76 42 70  3 92 43 59 52 61 34 29 99  1 50 36 18  4  2 82 39  5 58 84 17 19
 24 81 32 67 13 64 85 95 15 62 14 68 60 73 22 10 89 16 93 31 96 97 48 69 88
 41 21 57 28 35 66 74  6 71 56 44 11 27 46 20 55 94  9  8 54 25 86 91 47 63]
Value - initial: 7984337, final: 1039851, improveup: 7.67834718628

data-line;i;7984337;f;1039851;t;0.72500705719;c;-2;fv;[1039851L];cv;-1;imp;7.67834718628;type;rvnd;inum;1;w;1

time;0.72500705719;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
