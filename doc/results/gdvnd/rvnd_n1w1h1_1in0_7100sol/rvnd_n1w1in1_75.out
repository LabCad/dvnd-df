pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:75, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 7838756-[53 77  6 99 13 60 83 76 47 71 52 87 74 43 38 68 40 28  7 98 94 58 78 14 36
 29  3 26 64 86 73 21 51 48 42 10 95 37 24 46 96 61 63 45 75 70 81 57 35 30
 41 34 84 72 15 89  5 50 31 97 66  1 25 85 55  0 93 82 62 44 19 33 90  9 67
 92 12  4 79 56 49 91  8 22 80 11 23 20 18 59 69  2 65 27 32 39 54 16 88 17] - 7838756
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f6022c36ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 7838756-[53 77  6 99 13 60 83 76 47 71 52 87 74 43 38 68 40 28  7 98 94 58 78 14 36
 29  3 26 64 86 73 21 51 48 42 10 95 37 24 46 96 61 63 45 75 70 81 57 35 30
 41 34 84 72 15 89  5 50 31 97 66  1 25 85 55  0 93 82 62 44 19 33 90  9 67
 92 12  4 79 56 49 91  8 22 80 11 23 20 18 59 69  2 65 27 32 39 54 16 88 17]
Final time: 1.98186087608s - Best: 999457-[53 90 62 14 83 40 23 26 87 78 12  0 49 33 80 37 65  7 51 45 60 73  6 71 56
 30 77 98 44 32 67 13 64 85 95 15 76 42 63 84 58  2 82 39  5 17 24 19 46 11
 27 20 55 94  9  8 54 25 86 91 47  1 18 36 50 99 29 34 61  4 52 59 43 92  3
 70 38 72 10 89 16 93 31 96 97 48 69 88 22 41 21 57 28 35 66 74 75 79 68 81]
Value - initial: 7838756, final: 999457, improveup: 7.84301475701

data-line;i;7838756;f;999457;t;1.98186087608;c;-2;fv;[999457L];cv;-1;imp;7.84301475701;type;rvnd;inum;1;w;1

time;1.98186087608;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
