pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:83, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 8225692-[61 92 22  0 47  4 15 93 28 45 68 96 60 78 55 51 72 38 44  7 91 42 69  1 70
 33 20 13 82 85 41 25 64  8 26 71 76  6 49 88 12 46 30 14 73 99 10 98 95 27
 32 16 87 48 79 83 65 67 52 34 97 86 54 89  2 80 56 50 36 59 62 31 63 75 21
 35  9 40 77 23 90 11 94 58 53 18 39 37 17 66 84 57 29 74 81 19  3 24 43  5] - 8225692
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f59d6b09ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 8225692-[61 92 22  0 47  4 15 93 28 45 68 96 60 78 55 51 72 38 44  7 91 42 69  1 70
 33 20 13 82 85 41 25 64  8 26 71 76  6 49 88 12 46 30 14 73 99 10 98 95 27
 32 16 87 48 79 83 65 67 52 34 97 86 54 89  2 80 56 50 36 59 62 31 63 75 21
 35  9 40 77 23 90 11 94 58 53 18 39 37 17 66 84 57 29 74 81 19  3 24 43  5]
Final time: 1.05556297302s - Best: 1020641-[61 36 50 29 99  1 18  4 52 59 43 92  3 70 42 76 15 62 53 90 38 72 14 83 40
 23 26 87 78 12  0 49 93 31 96 97 48 69 88 89 16 10 33 80 37 65  7 51 45 75
 79 77 30 98 44 32 67 13 81 24 19  9 20 46 11 27 55 94 25 86 54  8  2 82 39
  5 17 84 58 63 95 85 68 60 73  6 74 66 35 28 57 21 41 22 71 56 64 91 47 34]
Value - initial: 8225692, final: 1020641, improveup: 8.05933917999

data-line;i;8225692;f;1020641;t;1.05556297302;c;-2;fv;[1020641L];cv;-1;imp;8.05933917999;type;rvnd;inum;1;w;1

time;1.05556297302;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
