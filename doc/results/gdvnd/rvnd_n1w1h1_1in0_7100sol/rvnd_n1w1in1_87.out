pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:87, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 9036388-[82 36 21 11 34 69 90 24 93 44 70 35 18  6 29 95 22 68 23  5 47 50 78  2 26
 60 72 16 75 17 19 87 27 99 59 51 25 37 46 48 10 38 61  3 71 89 88 13 55 64
 84 80 41 12 43 63 28 97 67 73 77 54  9  0  7 53 94 56 92 66 85 65 42 15 83
 58 39 74  8 30 79 49 20 81 31 91 57  4 32 96  1 52 14 76 45 86 98 33 40 62] - 9036388
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f6c4cbb1ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 9036388-[82 36 21 11 34 69 90 24 93 44 70 35 18  6 29 95 22 68 23  5 47 50 78  2 26
 60 72 16 75 17 19 87 27 99 59 51 25 37 46 48 10 38 61  3 71 89 88 13 55 64
 84 80 41 12 43 63 28 97 67 73 77 54  9  0  7 53 94 56 92 66 85 65 42 15 83
 58 39 74  8 30 79 49 20 81 31 91 57  4 32 96  1 52 14 76 45 86 98 33 40 62]
Final time: 1.70515203476s - Best: 993304-[82  2 39  5 58 84 63 15 62 53 90 76 42 70  3 92 43 59 52 61 36 18 50 29 99
  1 47 91 54 86 25 94 55 27 11 46 20  9  8 19 24 81 13 67 32 44 98 30 77 79
 75 45 51  7 65 37 33 80 26 23 87 78 12  0 49 93 31 96 97 48 69 88 89 16 10
 22 41 21 57 28 35 66 74  6 73 60 71 56 64 85 95 68 14 83 40 72 38 17  4 34]
Value - initial: 9036388, final: 993304, improveup: 9.09730354453

data-line;i;9036388;f;993304;t;1.70515203476;c;-2;fv;[993304L];cv;-1;imp;9.09730354453;type;rvnd;inum;1;w;1

time;1.70515203476;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
