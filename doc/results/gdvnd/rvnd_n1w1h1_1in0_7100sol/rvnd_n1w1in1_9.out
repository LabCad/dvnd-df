pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:9, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 7984584-[42 53  0 31  9 75 12 52 80 18 90 43  2 93 68 50 17 13 15 48 58 56 34 69 24
 86 20 89 40 63  6 66 72 67 38 83 41  3 36 37 85  1 96 79 64 32 92 70 62 82
 44 91 99 88 94 39  8 45 95 16 59 11 74 73 46 81 97 25 84 77 23 61 19 29 47
 30 10 87 22  5 55 21 65 60 76 71 28 57 27  4 78 49  7 51 26 54 14 98 35 33] - 7984584
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f15a68c0ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 7984584-[42 53  0 31  9 75 12 52 80 18 90 43  2 93 68 50 17 13 15 48 58 56 34 69 24
 86 20 89 40 63  6 66 72 67 38 83 41  3 36 37 85  1 96 79 64 32 92 70 62 82
 44 91 99 88 94 39  8 45 95 16 59 11 74 73 46 81 97 25 84 77 23 61 19 29 47
 30 10 87 22  5 55 21 65 60 76 71 28 57 27  4 78 49  7 51 26 54 14 98 35 33]
Final time: 0.877398014069s - Best: 982370-[42  3 43 59 52  4  2 82 39  5 17 84 58 63 76 90 53 62 15 95 85 64 13 67 32
 44 98 30 77 79 75 60 73  6 74 66 35 28 57 21 41 22 88 69 48 97 96 31 93 16
 89 10 37 65  7 51 80 33 49  0 12 78 87 26 23 40 83 72 38 70 92 61 36 18 50
 34 29 99  1 47 91 54 86 25 94 55 27 11 46 20  9  8 19 24 81 56 71 45 14 68]
Value - initial: 7984584, final: 982370, improveup: 8.12787849792

data-line;i;7984584;f;982370;t;0.877398014069;c;-2;fv;[982370L];cv;-1;imp;8.12787849792;type;rvnd;inum;1;w;1

time;0.877398014069;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
