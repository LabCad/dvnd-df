pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:74, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 8542301-[88 34 54 82 26 58 57  5 90 73 18 47 63 43  1 37 94  8 76 89 42 91 83 22 85
 62 27 48 67 32 56 81 77 51 30 79  4 10 16  7 59 23 74 99 31 92 49 98 29 33
 24 69 39 75 86 20 68  6 78  9 65 36 96 40  0 60 53 25 13 21 46 41 72 44  3
 19 93 38 61 55 87 14 17 12 15 28 66 52 70 95 71 45 80 64 84 50 11  2 35 97] - 8542301
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f50dcd1ead0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 8542301-[88 34 54 82 26 58 57  5 90 73 18 47 63 43  1 37 94  8 76 89 42 91 83 22 85
 62 27 48 67 32 56 81 77 51 30 79  4 10 16  7 59 23 74 99 31 92 49 98 29 33
 24 69 39 75 86 20 68  6 78  9 65 36 96 40  0 60 53 25 13 21 46 41 72 44  3
 19 93 38 61 55 87 14 17 12 15 28 66 52 70 95 71 45 80 64 84 50 11  2 35 97]
Final time: 1.08766198158s - Best: 1034255-[88 10 89 16 93 49  0 26 23 87 12 78 40 83 14 62 53 90 76 42 63 15 95 85 64
 77 30 98 44 32 67 13 81 17 84 58  2 82 39  5 24 19 46 11 27 20 55 94  9  8
 54 25 86 91 47  1 99 29 34 50 18 36 61  4 52 59 43 92  3 70 38 72 68 45 51
  7 65 37 80 33 31 96 97 48 69 22 41 21 57 28 35 66 74  6 73 60 79 75 71 56]
Value - initial: 8542301, final: 1034255, improveup: 8.25937607263

data-line;i;8542301;f;1034255;t;1.08766198158;c;-2;fv;[1034255L];cv;-1;imp;8.25937607263;type;rvnd;inum;1;w;1

time;1.08766198158;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
