pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:53, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 7515258-[67 59 83 15 66 35  1 38 92 33 50 39 47 84 64  5 94 82 98 69 45 61 85  9 99
 58 78 36 97 49 93 11 73 57  0 71 62 12  4  6 90 18 76 86 74  7 10 13 79 88
 95 40  3 63 26  2 17 25 53 16 96 19 60 68 56  8 23 22 24 52 80 55 48 89 75
 51 77 54 72 32 14 43 34 37 21 27 81 42 31 87 65 30 29 20 91 44 28 70 41 46] - 7515258
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7fbdd3756ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 7515258-[67 59 83 15 66 35  1 38 92 33 50 39 47 84 64  5 94 82 98 69 45 61 85  9 99
 58 78 36 97 49 93 11 73 57  0 71 62 12  4  6 90 18 76 86 74  7 10 13 79 88
 95 40  3 63 26  2 17 25 53 16 96 19 60 68 56  8 23 22 24 52 80 55 48 89 75
 51 77 54 72 32 14 43 34 37 21 27 81 42 31 87 65 30 29 20 91 44 28 70 41 46]
Final time: 1.27688598633s - Best: 1048593-[67 13 32 44 98 77 30 56 71 79 75 45 51  7 65 37 33 80 26 23 87 78 12  0 49
 93 31 96 97 48 69 88 89 16 10 22 41 21 57 28 35 66 74  6 73 60 68 14 62 53
 90 76 42 63 84 58  2 82 39  5 17 24 19  8 54 25 86 91 47  1 18 36 50 99 29
 34 61 59 92 70  3 43 52  4  9 94 55 20 46 27 11 81 85 95 15 38 72 40 83 64]
Value - initial: 7515258, final: 1048593, improveup: 7.16699234117

data-line;i;7515258;f;1048593;t;1.27688598633;c;-2;fv;[1048593L];cv;-1;imp;7.16699234117;type;rvnd;inum;1;w;1

time;1.27688598633;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
