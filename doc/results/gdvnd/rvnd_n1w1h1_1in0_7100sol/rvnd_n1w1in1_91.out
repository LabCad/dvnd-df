pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:91, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 9118131-[84  3 27 80  1 50 98 76 49 52 44 57 63 18 41 66 23 88 95 20  9 17  7 21 93
 55 74 19 31 82 85 46  5 35 36 14 61 73 34 71 99 37 92 26 54 22 51 48 25 28
 29 56 10 96 59 62 64 53 87 43 13 33 30 78 68 79 12 70 45 86 90 89 47 16 81
 65  0 77 67 40 72 24 11  6 91  8 58 75 42  4 15 60 94 38  2 32 69 97 39 83] - 9118131
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7fc5f9de0ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 9118131-[84  3 27 80  1 50 98 76 49 52 44 57 63 18 41 66 23 88 95 20  9 17  7 21 93
 55 74 19 31 82 85 46  5 35 36 14 61 73 34 71 99 37 92 26 54 22 51 48 25 28
 29 56 10 96 59 62 64 53 87 43 13 33 30 78 68 79 12 70 45 86 90 89 47 16 81
 65  0 77 67 40 72 24 11  6 91  8 58 75 42  4 15 60 94 38  2 32 69 97 39 83]
Final time: 1.05550599098s - Best: 1007809-[84 58  5 39 82  2  4 52 61 36 50 18  1 99 29 34 59 43 92  3 70 42 76 15 62
 53 90 38 72 14 83 40 23 26 87 78 12  0 49 33 80 37 65  7 51 45 73 60 71 56
 30 98 44 32 67 13 64 85 95 17 24 19  9  8 54 86 25 94 55 20 27 11 46 81 77
 79 75  6 74 66 35 28 57 21 69 48 97 96 31 93 16 89 10 88 41 22 68 63 91 47]
Value - initial: 9118131, final: 1007809, improveup: 9.04747923466

data-line;i;9118131;f;1007809;t;1.05550599098;c;-2;fv;[1007809L];cv;-1;imp;9.04747923466;type;rvnd;inum;1;w;1

time;1.05550599098;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
