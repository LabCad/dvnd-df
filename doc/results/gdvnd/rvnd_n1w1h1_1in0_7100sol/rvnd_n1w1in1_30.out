pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:30, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 8039250-[ 0 45 31 14 47 55 69 85 51 67 89 60 52 46 77 30 44 58 65 84 72 70 50 17  6
 15 99 42 75 26 91 64 96 81  1 12 79 16 22 73 19 48 39 11 90 59  7 40 21 66
 97 76 34 87 20 92 36 98 27 80 94 35 13 24  4 56  9 10 86 61 53  5 63 38  2
 78 32 23 93 49 37 74 82 88 95 57 41 43 18  3 68  8 25 28 62 54 29 83 71 33] - 8039250
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f8be8843ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 8039250-[ 0 45 31 14 47 55 69 85 51 67 89 60 52 46 77 30 44 58 65 84 72 70 50 17  6
 15 99 42 75 26 91 64 96 81  1 12 79 16 22 73 19 48 39 11 90 59  7 40 21 66
 97 76 34 87 20 92 36 98 27 80 94 35 13 24  4 56  9 10 86 61 53  5 63 38  2
 78 32 23 93 49 37 74 82 88 95 57 41 43 18  3 68  8 25 28 62 54 29 83 71 33]
Final time: 1.05221199989s - Best: 1020542-[ 0 49 33 80 26 23 87 12 78 40 83 14 62 53 90 76 42 70  3 92 43 59 52  4 61
 36 18 50 29 99  1 47 91 86 25 54  8  9 94 55 20 27 11 46 19 24 81 13 67 32
 44 98 30 77 64 85 95 84 17  5 39 82  2 58 63 15 68 45 51  7 65 37 10 89 16
 93 31 96 97 48 69 88 22 41 21 57 28 35 66 74  6 73 60 71 56 79 75 72 38 34]
Value - initial: 8039250, final: 1020542, improveup: 7.87743179605

data-line;i;8039250;f;1020542;t;1.05221199989;c;-2;fv;[1020542L];cv;-1;imp;7.87743179605;type;rvnd;inum;1;w;1

time;1.05221199989;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
