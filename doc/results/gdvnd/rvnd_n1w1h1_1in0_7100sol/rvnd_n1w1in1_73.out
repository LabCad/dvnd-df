pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:73, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 8294477-[79 92 25 91 88 60 77 33  1 89 47 10  7 76 27 65 73 56 30 70 96 15 38 99 94
 74 16  5 49 48  2 62 86 63 97 82  8 23 83 52 53 11 34 78 40 93 37 71 69 44
 31  6 18 64 66 58  4 98 39 59 41 14 81 50 51 36 61 22 68 24  3 55 19 84 43
 29 75 45 57 67 87 17 54 72 12 85 90 20 46 13 28 32 42 80 26 95 35  9 21  0] - 8294477
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7fd1b9815ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 8294477-[79 92 25 91 88 60 77 33  1 89 47 10  7 76 27 65 73 56 30 70 96 15 38 99 94
 74 16  5 49 48  2 62 86 63 97 82  8 23 83 52 53 11 34 78 40 93 37 71 69 44
 31  6 18 64 66 58  4 98 39 59 41 14 81 50 51 36 61 22 68 24  3 55 19 84 43
 29 75 45 57 67 87 17 54 72 12 85 90 20 46 13 28 32 42 80 26 95 35  9 21  0]
Final time: 1.01558709145s - Best: 947093-[79 77 30 98 44 32 67 13 64 85 95 15 62 53 90 76 42 63 84 58  2 82 39  5 17
 24 19  9  8 54 25 86 91 47  1 99 29 50 18 36 61  4 52 59 43 92  3 70 38 72
 14 83 40 78 12 87 23 26  0 49 93 31 96 97 48 69 88 89 16 10 33 80 37 65  7
 51 45 60 73 22 41 21 57 28 35 66 74  6 71 56 75 68 81 46 11 27 20 55 94 34]
Value - initial: 8294477, final: 947093, improveup: 8.75782737281

data-line;i;8294477;f;947093;t;1.01558709145;c;-2;fv;[947093L];cv;-1;imp;8.75782737281;type;rvnd;inum;1;w;1

time;1.01558709145;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
