pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:70, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 7822895-[27 97 31 24  5 48 69 92 81 85 34 36 61 88 98 60 93 83 70 62 91 76  6 66 16
 94 21 45 82 47 40 64 74 51 12 53  7 29 79  8 37 59  0 19 32 43 17 39 86 41
 10 30 67 23 73 96 42 14 26 49 55 13 56 65 52 87 54 72 77 44 22 25 57  4 11
 80 90 15 95 50 68 58 18 75 33 46 99  2  1  9 78 84 71 63 28 20 38 35 89  3] - 7822895
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f351e09ead0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 7822895-[27 97 31 24  5 48 69 92 81 85 34 36 61 88 98 60 93 83 70 62 91 76  6 66 16
 94 21 45 82 47 40 64 74 51 12 53  7 29 79  8 37 59  0 19 32 43 17 39 86 41
 10 30 67 23 73 96 42 14 26 49 55 13 56 65 52 87 54 72 77 44 22 25 57  4 11
 80 90 15 95 50 68 58 18 75 33 46 99  2  1  9 78 84 71 63 28 20 38 35 89  3]
Final time: 0.641360998154s - Best: 994707-[27 11 46 20  9 25 86 54  8 19 24 17  5 39 82  2 58 84 63 76 90 53 62 15 95
 85 64 13 67 32 44 98 30 77 79 75 60 73 22 41 88 69 48 97 96 31 93 16 89 10
 37 65  7 51 80 33 49  0 12 78 87 26 23 40 83 72 38 70  3 92 43 59 61 36 18
 50 34 29 99  1 47 91  4 52 42 14 68 45 21 57 28 35 66 74  6 71 56 81 94 55]
Value - initial: 7822895, final: 994707, improveup: 7.86452191449

data-line;i;7822895;f;994707;t;0.641360998154;c;-2;fv;[994707L];cv;-1;imp;7.86452191449;type;rvnd;inum;1;w;1

time;0.641360998154;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
