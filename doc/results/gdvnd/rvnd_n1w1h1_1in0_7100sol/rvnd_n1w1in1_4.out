pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:4, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 8522694-[82 78 83 81 97 68 41 90 10 53 50 65 85 71 51 37 18 16 74 87 34 98 99 21 45
 11 13 30 55 44 91 66 23 39 12 22  2 49 58 43 73 80 15 64 40 79  7  3 86 28
 38 26 76 47 14 93  0 31 77 48 24 32 95 57 42  1 54  4 25 27 35 46 17 60 69
 52 56 89 61 20 96 70  6  8 19 62 67 75  5  9 88 72 36 33 59 94 29 84 63 92] - 8522694
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f203b120ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 8522694-[82 78 83 81 97 68 41 90 10 53 50 65 85 71 51 37 18 16 74 87 34 98 99 21 45
 11 13 30 55 44 91 66 23 39 12 22  2 49 58 43 73 80 15 64 40 79  7  3 86 28
 38 26 76 47 14 93  0 31 77 48 24 32 95 57 42  1 54  4 25 27 35 46 17 60 69
 52 56 89 61 20 96 70  6  8 19 62 67 75  5  9 88 72 36 33 59 94 29 84 63 92]
Final time: 0.965912103653s - Best: 985230-[82  5 39  2  4 52 59 43  3 70 42 76 90 53 62 15 95 85 64 13 67 32 44 98 77
 30 56 71  6 74 66 35 73 60 45 51  7 65 37 80 33 10 16 89 88 69 48 97 96 31
 93 49  0 12 78 87 26 23 40 83 14 72 38 63 58 84 17 24 19  9  8 54 25 86 91
 18 50 36 61 34 29 99  1 47 94 55 20 46 27 11 81 79 75 22 41 21 57 28 68 92]
Value - initial: 8522694, final: 985230, improveup: 8.6504613136

data-line;i;8522694;f;985230;t;0.965912103653;c;-2;fv;[985230L];cv;-1;imp;8.6504613136;type;rvnd;inum;1;w;1

time;0.965912103653;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
