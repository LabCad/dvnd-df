pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:84, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 8456992-[33 92 31  6 34 19 74 25 38 15 22 44 93 23 89 14 57 53 73 50  5 21 63 98 94
 36 16 58 83  0  9 72 88 78 82 95 55 41 61 37 85 17 81 30 49 26 97 71 80 77
 76 12 68 35 86 24 39  1  2 51 11 64 10 42 90 45  7 56 96 66 27 99  3 52 18
 79 65 87 47 75  8 13 60 43 32 54 91 48 67 20 84  4 70 46 62 28 69 40 29 59] - 8456992
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f463fcacad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 8456992-[33 92 31  6 34 19 74 25 38 15 22 44 93 23 89 14 57 53 73 50  5 21 63 98 94
 36 16 58 83  0  9 72 88 78 82 95 55 41 61 37 85 17 81 30 49 26 97 71 80 77
 76 12 68 35 86 24 39  1  2 51 11 64 10 42 90 45  7 56 96 66 27 99  3 52 18
 79 65 87 47 75  8 13 60 43 32 54 91 48 67 20 84  4 70 46 62 28 69 40 29 59]
Final time: 1.06015205383s - Best: 976659-[33 80 51  7 65 37 10 16 89 88 69 48 97 96 31 93 49  0 26 23 87 12 78 40 83
 72 38 90 53 62 15 76 42 70  3 92 43 59 52  4 61 34 29 99 50 36 18  1 47 91
 86 25 54  8  9 19 24 17  5 39 82  2 58 84 95 85 64 13 67 32 44 98 30 77 56
 71 79 75 60 73  6 74 66 35 28 57 21 41 22 45 68 14 63 81 46 27 11 20 94 55]
Value - initial: 8456992, final: 976659, improveup: 8.65910414996

data-line;i;8456992;f;976659;t;1.06015205383;c;-2;fv;[976659L];cv;-1;imp;8.65910414996;type;rvnd;inum;1;w;1

time;1.06015205383;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
