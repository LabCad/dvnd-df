pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:5, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 7530964-[67 13 92 61 23 74 43 82 15 34 20 35 78 37 40 31 93 66 72 14 99  4 32 64 73
 63 62  9 57  8 68 28 11  7 56 27 83  0 33 84 12 17 22 95 29 21 86 55 81 44
 98  6 36 51 77 80 89 85 50 76 60 42 18 39 75 30 47  5 90  2 46 10 87 16 70
 19 26 48  1 79 52 25 91 54 53 88 71 38 24 69 58  3 96 49 41 59 65 97 45 94] - 7530964
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f80f1489ad0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 7530964-[67 13 92 61 23 74 43 82 15 34 20 35 78 37 40 31 93 66 72 14 99  4 32 64 73
 63 62  9 57  8 68 28 11  7 56 27 83  0 33 84 12 17 22 95 29 21 86 55 81 44
 98  6 36 51 77 80 89 85 50 76 60 42 18 39 75 30 47  5 90  2 46 10 87 16 70
 19 26 48  1 79 52 25 91 54 53 88 71 38 24 69 58  3 96 49 41 59 65 97 45 94]
Final time: 1.06659197807s - Best: 982566-[67 13 32 44 98 30 77 64 85 95 15 62 53 90 76 42 63 84 58  5 39 82  2  4 54
 25 86 91 47  1 99 29 34 50 18 36 61 52 59 43 92  3 70 38 72 14 83 40 23 26
 87 78 12  0 49 93 31 96 97 48 69 88 89 16 10 33 80 37 65  7 51 45 60 73 35
 66 74  6 71 56 75 79 17 24 19  8  9 94 55 20 46 27 11 81 68 22 21 57 28 41]
Value - initial: 7530964, final: 982566, improveup: 7.66458843477

data-line;i;7530964;f;982566;t;1.06659197807;c;-2;fv;[982566L];cv;-1;imp;7.66458843477;type;rvnd;inum;1;w;1

time;1.06659197807;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
