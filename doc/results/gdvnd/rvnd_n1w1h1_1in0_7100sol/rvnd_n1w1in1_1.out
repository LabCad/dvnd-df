pydf_home: /home/rodolfo/git/Sucuri
simple_pycuda_home: /home/rodolfo/git/simple-pycuda
wamca2016path: /home/rodolfo/git/wamca2016/
localpath: /home/rodolfo/git/dvnd-df/code/dvnd-df/src/
WAMCAPATH:/home/rodolfo/git/wamca2016/
param: {solution_index:1, solution_instance_index:1, multi_gpu:True, goal:False, problem_name:ml, number_of_moves:10, device_count:2, solver:rvnd, mpi_enabled:True, workers:1}
Using already created file:  wamca2016lib.so
Size: 100 - file name: 02_kroD100.tsp

Value - initial: 7757173-[36 83 53 89 18 71 47 88 73 64 80 99  7 75 85 95  5 78 14 48 51 31 65  3 28
 72 70 90  1 15 82 30  2 27 94 79  6 57 22 40 43 39  0 23 98 86 45 50 49 87
 16 63 33 17 61 34 25 29 11 26 92  9 93 62 96 20 59 66 42 10 81 84 54 19 74
 55  8 76 41 68 38 58 13 67 24 52 77 69 60 91 12 21  4 35 32 97 44 56 37 46] - 7757173
Solver: RVND, number of workers: 1
Setting feeder affinity
I am the master. There are 1 mpi processes. (hostname = gpu01)
Roots [<pyDF.nodes.Feeder object at 0x7f0d73e2ead0>]
Starting 0
Main loop
I am worker 0
GPU0
set random seed!
Initial: 7757173-[36 83 53 89 18 71 47 88 73 64 80 99  7 75 85 95  5 78 14 48 51 31 65  3 28
 72 70 90  1 15 82 30  2 27 94 79  6 57 22 40 43 39  0 23 98 86 45 50 49 87
 16 63 33 17 61 34 25 29 11 26 92  9 93 62 96 20 59 66 42 10 81 84 54 19 74
 55  8 76 41 68 38 58 13 67 24 52 77 69 60 91 12 21  4 35 32 97 44 56 37 46]
Final time: 1.03198504448s - Best: 1036980-[36 50 18  1 99 29 34 61 59 43  3 42 76 90 53 62 15 63 58  2 82 39  5 17 84
 95 85 64 77 79 75 71 56 30 98 44 32 67 13 81 24 19 46 11 27 20 55 94  9  8
 25 86 54  4 52 92 70 38 72 83 40 78 12 87 23 26  0 49 33 80 37 65 51  7 22
 41 88 10 89 16 93 31 96 97 48 69 21 57 28 35 66 74  6 73 60 45 68 14 91 47]
Value - initial: 7757173, final: 1036980, improveup: 7.48054253698

data-line;i;7757173;f;1036980;t;1.03198504448;c;-2;fv;[1036980L];cv;-1;imp;7.48054253698;type;rvnd;inum;1;w;1

time;1.03198504448;man_time;0;neigh_time;0
man_time;0;man_merge_sol;0;man_best_sol;0;man_combine_sol;0

Waiting [0]
Terminating workers True 0 0
MPI TERMINATING
